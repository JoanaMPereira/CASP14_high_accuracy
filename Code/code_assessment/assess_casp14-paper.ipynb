{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib\n",
    "\n",
    "from matplotlib import rc\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy import stats\n",
    "\n",
    "rc('text', usetex=False)\n",
    "rc('font', family='Arial')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv('https://predictioncenter.org/casp14/targetlist.cgi?type=csv', sep = ';', error_bad_lines = False)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelled_targets = []\n",
    "for index, row in targets.iterrows():\n",
    "    if 'canceled' in row.Description or 'Canceled' in row.Description:\n",
    "        cancelled_targets.append(row.Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_casp_zscore_table(target_casp, cancelled_targets, mode = None, domains_only = False):\n",
    "    \n",
    "    if mode is not None:\n",
    "        table = 'CASP{}/CASP{}_templates_table.csv'.format(target_casp, target_casp)\n",
    "    else:\n",
    "        table = 'CASP{}/CASP{}_Zscores_table.csv'.format(target_casp, target_casp)\n",
    "\n",
    "    df = pd.read_csv(table, sep='\\t').reset_index(drop=True)\n",
    "    \n",
    "    if domains_only:\n",
    "        # remove the multidomain lines\n",
    "        df = df[df.Target.str.contains(\"-D\")]\n",
    "\n",
    "    # remove the NaN models\n",
    "    df = df[df['Model'].notna()]\n",
    "    \n",
    "    # add model ranking based on group\n",
    "    if mode is None:            \n",
    "        df['Model_GR_rank'] = [int(model.split('_')[-1].split('-')[0]) if model != 'Starting' else 0 for model in df.Model]\n",
    "    else:\n",
    "        # for the template tables, add as the group either that they are template, or the real structure\n",
    "        df['GR#'] = ['TMP' if type(i) == str else 'REAL' for i in df.pdb]\n",
    "                \n",
    "    #df['Input_target'] = [target.replace('R', 'T') for target in df.Target]\n",
    "    \n",
    "    # exclude the cancelled targets    \n",
    "    df = df[~df['Target'].isin(cancelled_targets)]\n",
    "    df = df[df['Target'].notna()]\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_casp = '14'\n",
    "domains_only = True\n",
    "do_null = True\n",
    "\n",
    "if domains_only:\n",
    "    figures_folder = 'CASP{}/highres_figs_EXCLUDING_MULTIDOMAINS'.format(target_casp)\n",
    "else:\n",
    "    figures_folder = 'CASP{}/highres_figs'.format(target_casp)\n",
    "\n",
    "if not do_null:\n",
    "    figures_folder = '{}_NO_NULL'.format(figures_folder)\n",
    "    \n",
    "if not os.path.isdir(figures_folder):\n",
    "    os.mkdir(figures_folder)\n",
    "\n",
    "df = load_casp_zscore_table(target_casp, cancelled_targets, domains_only = domains_only)\n",
    "df_templates = load_casp_zscore_table(target_casp, cancelled_targets, domains_only = domains_only, mode = 'template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns of the templates table\n",
    "new_names = []\n",
    "for col in df_templates.columns:\n",
    "    if '_GD' in col:\n",
    "        col = col.replace('Template_', '')\n",
    "    elif 'Template' in col and '_score' not in col:\n",
    "        col = col.replace('Template', 'Model')\n",
    "    new_names.append(col)\n",
    "df_templates.columns = new_names\n",
    "\n",
    "df_templates = df_templates.set_index('Model')\n",
    "df_templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Backbone and sidechain modelling analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well do the methods build sidechains and backbones?\n",
    "\n",
    "For **backbones**, we calculated three parameters that evaluate the local geometry of the models and compare it to the target. These are:\n",
    "    - Backbone geometry score from Tristan's and Randy's CASP13 paper (BBscore): It evaluates the deviation of the models' backbone dihedral and torsion angles when compared to the target\n",
    "    - DipDiff: we developed this metric and is based on the difference of local DipScores of the model when compared to the target. DipScores (Pereira and Lamzin, IUCrJ 2017) are a measure of conformation likelihood for a given CA, and is based on the interatomic distances between its adjacent CA and O atoms. \n",
    "    - CaBLAMdiff: we developed this metric to compare the CaBLAM scores with the DipScores and DipDiff. CaBLAM scores CA based on the torsion angles between adjacent CA and O atoms\n",
    "\n",
    "For **sidechains**, we did not develop any metric and use only:\n",
    "    - Sidechain geometry score from Tristan's and Randy's CASP13 paper (SCscore): It evaluates the deviation of the models sidechain chi angles when compared to the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***This analysis was carried out***:\n",
    " - only accounting with the 1st models submitted by each group and ignored refined models!\n",
    " - for groups that submitted models for at least 10 targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1st = df.loc[(df.Model_GR_rank == 1) & (df.Model.str.startswith('T'))]\n",
    "#df_1st = df.loc[(df.Model_GR_rank == 1)]\n",
    "df_1st = df_1st.groupby(['GR#']).filter(lambda s: s['GR#'].count()>=10)\n",
    "df_1st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Backbone geometry quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1. Target boxplots for backbone scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targets_boxplot(df_1st, templates_df, target_parameter):\n",
    "    \n",
    "    sorted_nb = df_1st.groupby(['Target'])[target_parameter].median().sort_values(ascending=False)\n",
    "    \n",
    "    print('Median median {}:'.format(target_parameter), sorted_nb.median())\n",
    "    \n",
    "#     plt.figure(figsize=(15, 5))\n",
    "#     g = sns.boxplot(x='Target', y=target_parameter, color = 'whitesmoke', data = df_1st, fliersize=2, dodge=False, order=sorted(list(sorted_nb.index)), linewidth=1)\n",
    "#     g.axhline(0, linestyle=':', color='black')\n",
    "    \n",
    "#     s = sns.stripplot(x='Target', y=target_parameter, hue = 'Template_score', palette= 'Greens', linewidth=0.3, size = 5, data = df_templates.loc[df_templates['GR#'] == 'TMP'], order=sorted(list(sorted_nb.index)))\n",
    "#     #s = sns.stripplot(x='Target', y=target_parameter, color='orange', linewidth=0.3, size = 5, data = df_1st.loc[df_1st['GR#'] == '427'], order=sorted(list(sorted_nb.index)))\n",
    "#     s.get_legend().remove()\n",
    "    \n",
    "#     plt.xticks(rotation=90)\n",
    "#     plt.title('General boxplot of Targets {}'.format(target_parameter))\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(\"{}/targets_boxplot_{}.pdf\".format(figures_folder, target_parameter))\n",
    "\n",
    "#     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_parameters = ['Model_DipDiff','Model_BBscore', 'GDT_HA']\n",
    "for p in target_parameters:\n",
    "    targets_boxplot(df_1st, df_templates, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_parameters = ['Model_DipDiff']\n",
    "compare_parameters = ['GDT_HA', 'Model_BBscore']\n",
    "for p in target_parameters:   \n",
    "    for i in compare_parameters:\n",
    "    \n",
    "        plt.figure(figsize=(3.5,3))\n",
    "        plt.scatter(df_1st[p], df_1st[i], s=1, c='silver', label='Models')\n",
    "        #plt.scatter(df_1st[df_1st['GR#'] == '427'][p], df_1st[df_1st['GR#'] == '427'][i], s=1, c='orange', label='AlphaFold2')\n",
    "        try:\n",
    "            plt.scatter(df_templates[p], df_templates[i], s=1, c='teal', label = 'Templates')\n",
    "        except:\n",
    "            pass\n",
    "        plt.xlabel('{}'.format(p))\n",
    "        if 'GD' in i:\n",
    "            ylab = 'Model_{}'.format(i)\n",
    "        else:\n",
    "            ylab = i\n",
    "            \n",
    "        plt.ylabel(i)\n",
    "        plt.legend()\n",
    "        \n",
    "        if 'GD' in i:\n",
    "            ymax = 100\n",
    "        else:\n",
    "            ymax = max(df_1st[i])\n",
    "        plt.ylim(0, ymax)    \n",
    "        plt.vlines(x=0, linestyle=':', color='k', ymin=0, ymax = 100)\n",
    "\n",
    "        plt.title('PCC for {} models: {}'.format(len(df_1st), round(df_1st.corr()[p][i], 3)))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"{}/scatter_{}_vs_{}.pdf\".format(figures_folder, p, ylab))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of models with DipDiff > 0: {}%'.format(len(df_1st.loc[df_1st.Model_DipDiff > 0])*100/len(df_1st)))\n",
    "print('Percentage of models with DipDiff > 0.1: {}%'.format(len(df_1st.loc[df_1st.Model_DipDiff > 0.1])*100/len(df_1st)))\n",
    "print('Percentage of models with DipDiff < 0: {}%'.format(len(df_1st.loc[df_1st.Model_DipDiff < 0])*100/len(df_1st)))\n",
    "print('Percentage of models with DipDiff = 0: {}%'.format(len(df_1st.loc[df_1st.Model_DipDiff == 0])*100/len(df_1st)))\n",
    "print()\n",
    "print('Percentage of templates with DipDiff > 0: {}%'.format(round(len(df_templates.loc[df_templates.Model_DipDiff > 0])*100/len(df_templates))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1st_posDipDiff = df_1st.loc[df_1st.Model_DipDiff > 0.1]\n",
    "plt.hist(df_1st_posDipDiff.GDT_HA, bins=range(0, 101, 2))\n",
    "plt.xlabel('GDT_HA')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('GDT_HA distribution for models with DipDiff > 0.1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Sidechain geometry quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. How is sidechain modelling affected by backbone geometric quality?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_parameters = ['Model_DipDiff', 'Model_BBscore']\n",
    "for p in target_parameters:\n",
    "    \n",
    "    plt.figure(figsize=(3.5,3))\n",
    "    plt.scatter(abs(df_1st[p]), df_1st.Model_SCscore, s=1, c='silver', label='Models')\n",
    "    #plt.scatter(abs(df_1st[df_1st['GR#'] == '427'][p]), df_1st[df_1st['GR#'] == '427'].Model_SCscore, s=1, c='orange', label='AlphaFold2')\n",
    "    plt.scatter(abs(df_templates[p]), df_templates.Model_SCscore, s=1, c='teal', label = 'Templates')\n",
    "    if 'Dipdiff' in p:\n",
    "        plt.xlabel('Absolute {}'.format(p))\n",
    "    else:\n",
    "        plt.xlabel(p)\n",
    "    plt.ylabel('Model_SCscore')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.title('PCC for {} models: {}'.format(len(df_1st), round(df_1st.corr()[p]['Model_SCscore'], 3)))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"{}/scatter_{}_vs_{}.pdf\".format(figures_folder, p, 'Model_SCscore'))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. Target boxplots for sidechain scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_parameters = ['Model_SCscore', 'GDC_SC']\n",
    "for p in target_parameters:\n",
    "    targets_boxplot(df_1st, df_templates, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Overall group rankings based on different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groups_boxplot(df_1st, target_parameter, target_color, topn = 10, palette = 'Blues_r'):\n",
    "    \n",
    "    sorted_nb = df_1st.groupby(['GR_name'])[target_parameter].median().sort_values(ascending=False)\n",
    "    \n",
    "    df_1st[target_color].fillna('?', inplace=True)\n",
    "    \n",
    "#     plt.figure(figsize=(9, 6))\n",
    "#     sns.barplot(data=df_1st, x=\"GR_name\", y=target_parameter, estimator=np.median, ci=None, dodge=False, linewidth=0.5, edgecolor=\"k\", hue=target_color, hue_order=reversed(sorted(list(set(df_1st[target_color])))), palette=palette, order=list(sorted_nb.index))\n",
    "#     plt.ylim(0, 2.5)\n",
    "#     plt.xlim(-1, len(sorted_nb.head(100)))\n",
    "#     plt.ylabel(target_parameter)\n",
    "#     plt.tick_params(\n",
    "#         axis='x',          # changes apply to the x-axis\n",
    "#         which='both',      # both major and minor ticks are affected\n",
    "#         bottom=False,      # ticks along the bottom edge are off\n",
    "#         top=False,         # ticks along the top edge are off\n",
    "#         labelbottom=False) # labels along the bottom edge are off\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(\"{}/groups_ranked_{}_colorby_{}.pdf\".format(figures_folder, target_parameter, target_color))\n",
    "\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "    \n",
    "    # Plot overall view, without xlabels\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sns.boxplot(x='GR_name', y=target_parameter, fliersize=2, hue= target_color, hue_order=reversed(sorted(list(set(df_1st[target_color])))), palette = palette, data = df_1st, dodge=False, order=list(sorted_nb.index), linewidth=1)\n",
    "    plt.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=False) # labels along the bottom edge are off\n",
    "    plt.xlabel('')\n",
    "    \n",
    "    if 'normalised' in target_parameter:\n",
    "        plt.ylim(0, 100)\n",
    "    else:\n",
    "        plt.ylim(0, plt.gca().get_ylim()[1])\n",
    "        \n",
    "    plt.title('General boxplot of {}, with groups colored based on {}'.format(target_parameter, target_color))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"{}/groups_boxplot_{}_colorby_{}.pdf\".format(figures_folder, target_parameter, target_color))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Now zoom in the top N\n",
    "    top_n = sorted_nb.head(topn)\n",
    "    df_top_n = df_1st.loc[df_1st.GR_name.isin(list(top_n.index))]\n",
    "    color_values = reversed(sorted(list(set(df_1st[target_color]))))\n",
    "    \n",
    "    accepted_values = [i for i in color_values if i != '?']\n",
    "    fig, ax = plt.subplots(1, len(accepted_values)+1, figsize=(5*(len(accepted_values)+1), 8), constrained_layout=True)\n",
    "    \n",
    "    sns.boxplot(ax=ax[0], fliersize=2, x='GR_name', y=target_parameter, hue= target_color, hue_order=reversed(sorted(list(set(df_1st[target_color])))), palette = palette, data = df_top_n, dodge=False, order=list(top_n.index), linewidth=1)\n",
    "    ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation='vertical')\n",
    "    ax[0].set_title('Top {} groups in general'.format(topn))\n",
    "    \n",
    "    if 'normalised' in target_parameter:\n",
    "        ax[0].set_ylim(0, 100)\n",
    "    else:\n",
    "        if ax[0].get_ylim()[1] > 4:\n",
    "            ax[0].set_ylim(0, 4)\n",
    "        else:\n",
    "            ax[0].set_ylim(0, ax[0].get_ylim()[1])\n",
    "    \n",
    "    # And now into the topN by target category, excluding those with an unknown (?) category\n",
    "    for i, value in enumerate(accepted_values):\n",
    "        curr_df = df_1st.loc[df_1st[target_color] == value]\n",
    "        sorted_nb = curr_df.groupby(['GR_name'])[target_parameter].median().sort_values(ascending=False)\n",
    "        top_n = sorted_nb.head(topn)\n",
    "        print(top_n)\n",
    "        df_top_n = curr_df.loc[curr_df.GR_name.isin(list(top_n.index))]\n",
    "        \n",
    "        sns.boxplot(ax=ax[i+1], fliersize=2, x='GR_name', y=target_parameter, hue=target_color, hue_order=reversed(sorted(list(set(df_1st[target_color])))), palette = palette, data = df_top_n, dodge=False, order=list(top_n.index), linewidth=1)\n",
    "        ax[i+1].set_xticklabels(ax[i+1].get_xticklabels(), rotation='vertical')       \n",
    "        ax[i+1].set_title('Top {} groups for {}:\\n{}'.format(topn, target_color, value))\n",
    "        \n",
    "        ax[i+1].set_ylim(ax[0].get_ylim()[0], ax[0].get_ylim()[1])\n",
    "    \n",
    "#     fig.title('General boxplot of {}, with groups colored based on {}'.format(target_parameter, target_color))\n",
    "    \n",
    "    plt.savefig(\"{}/groups_boxplot_{}_colorby_{}_top{}.pdf\".format(figures_folder, target_parameter, target_color, topn))\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Rank groups by the overall quality of their 1st model\n",
    "\n",
    "Done only for the groups that submitted models for at least 10 targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_parameters = ['S_geom_casp14', 'S_geom_casp13']\n",
    "target_color = ['GR_type', 'GR_DeepL','GR_classification']\n",
    "\n",
    "# target_parameters = ['S_geom_casp14']\n",
    "# target_color = ['GR_type']\n",
    "\n",
    "for p in target_parameters:\n",
    "    for c in target_color:\n",
    "        print('CURRENT PARAMETER: {}'.format(p))\n",
    "        print('COLORED BY:        {}'.format(c))\n",
    "        groups_boxplot(df_1st, p, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Check the effect of DipDiff on ranking \n",
    "\n",
    "Done only for the groups that submitted models for at least 10 targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_groups = ['ALPHAFOLD2', 'BAKER', 'BAKER-EXPERIMENTAL', 'BAKER-ROSETTASERVER', 'FEIG-R3', 'FEIG-R2', 'ZHANG', 'PROQ3D', 'PROQ2', 'VEROCNN-SELECT', 'P3DE']\n",
    "color_map = 'bwr_r'\n",
    "target_parameter = 'Model_DipDiff'\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sorted_nb = df_1st.groupby(['GR_name'])[target_parameter, 'GDT_HA', 'S_geom_casp14', 'S_geom_casp13'].median()\n",
    "\n",
    "sorted_nb = sorted_nb.sort_values(by='S_geom_casp14', ascending=False)\n",
    "sorted_nb['CASP14_rank'] = range(1, len(sorted_nb)+1)\n",
    "\n",
    "sorted_nb = sorted_nb.sort_values(by='S_geom_casp13', ascending=False)\n",
    "sorted_nb['CASP13_rank'] = range(1, len(sorted_nb)+1)\n",
    "\n",
    "sorted_nb['rank_diff'] = sorted_nb['CASP13_rank'] - sorted_nb['CASP14_rank']\n",
    "#norm = plt.Normalize(-max(sorted_nb['rank_diff'].min(), sorted_nb['rank_diff'].max()), max(sorted_nb['rank_diff'].min(), sorted_nb['rank_diff'].max()))\n",
    "norm = plt.Normalize(-min(sorted_nb['rank_diff'].min(), sorted_nb['rank_diff'].max()), min(sorted_nb['rank_diff'].min(), sorted_nb['rank_diff'].max()))\n",
    "\n",
    "ax = plt.scatter(sorted_nb['S_geom_casp13'],sorted_nb[target_parameter], c=sorted_nb['rank_diff'], cmap=color_map, norm=norm, edgecolors='k', linewidth=0.5, zorder=2)\n",
    "plt.hlines(y=0, xmin=0, xmax=100, linestyle=':', color='k', zorder=1)\n",
    "plt.xlim(-0.1,2.5)\n",
    "plt.ylim(min(df_1st[target_parameter]),max(df_1st[target_parameter]))\n",
    "plt.xlabel('Median method S_geom_casp13')\n",
    "plt.ylabel('Median method {}'.format(target_parameter))\n",
    "# Remove the legend and add a colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=color_map, norm=norm)\n",
    "sm.set_array([])\n",
    "ax.figure.colorbar(sm)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"{}/median_CASP13_vs_{}_colorby_rank_channge.pdf\".format(figures_folder, target_parameter))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# MAKE THE ZOOM\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = plt.scatter(sorted_nb['S_geom_casp13'],sorted_nb[target_parameter], c=sorted_nb['rank_diff'], cmap=color_map, norm=norm, edgecolors='k', linewidth=0.5, zorder=2)\n",
    "plt.hlines(y=0, xmin=0, xmax=100, linestyle=':', color='k', zorder=1)\n",
    "plt.xlim(0.6,1.0)\n",
    "\n",
    "if target_parameter == 'Model_DipDiff':\n",
    "    plt.ylim(-0.1, 0.05)\n",
    "else:\n",
    "    plt.ylim(0.2, 1.2)\n",
    "    \n",
    "plt.xlabel('Median method S_geom_casp13')\n",
    "plt.ylabel('Median method {}'.format(target_parameter))\n",
    "# Remove the legend and add a colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=color_map, norm=norm)\n",
    "sm.set_array([])\n",
    "ax.figure.colorbar(sm)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"{}/median_CASP13_vs_{}_colorby_rank_channge_zoom.pdf\".format(figures_folder, target_parameter))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "sorted_nb.sort_values(by='S_geom_casp14', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot bar plots separated by target difficulty for the top 10 groups\n",
    "\n",
    "Done only for the groups that submitted models for at least 10 targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groups_barplots(df_top1, parameter, rank_df = None, rank_parameter = 'S_geom_casp14', topn = 10, palette = 'Blues_r', logy = False):\n",
    "    \n",
    "    print('Ranked by: {}'.format(rank_parameter))\n",
    "    \n",
    "    if rank_df is None:\n",
    "        rank_df = df_top1\n",
    "        \n",
    "    sorted_nb = rank_df.groupby(['GR_name'])[rank_parameter].median().sort_values(ascending=False).head(topn)\n",
    "    \n",
    "    df_top1['Target_classification'] = df_top1['Target_classification'].fillna('NaN')\n",
    "        \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    g = sns.barplot(data=df_top1.loc[df_top1.Target_classification != 'NaN'], x=\"Target_classification\", y=parameter, errwidth=0.5, capsize=.02, estimator=np.median, order=['TBM-easy', 'TBM-hard', 'FM/TBM', 'FM'], ci='sd', linewidth=0.5, edgecolor=\"k\", hue=\"GR_name\", palette=palette, hue_order=list(sorted_nb.index))\n",
    "\n",
    "    plt.ylabel('Median {}'.format(parameter))\n",
    "    plt.xlabel('Target Classification')\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)    \n",
    "    \n",
    "    if 'LLG' in parameter:\n",
    "        cut = 60\n",
    "        if 'normalised' in parameter:\n",
    "            cut = cut*100/max(df_top1['deltaLLG'])\n",
    "        else:\n",
    "            g.axhline(cut, linestyle=':', color='k')\n",
    "    else:\n",
    "        g.axhline(0, linestyle=':', color='k')\n",
    "    \n",
    "    if 'GD' in parameter:\n",
    "        plt.ylim(0, 100)\n",
    "    elif 'DipDiff' in parameter:\n",
    "        plt.ylim(min(plt.ylim()), max(plt.ylim()))\n",
    "    else:\n",
    "        plt.ylim(0, max(plt.ylim()))\n",
    "    \n",
    "    if logy:\n",
    "        plt.yscale('log')\n",
    "        plt.ylim(0.001, max(plt.ylim()))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if logy:\n",
    "        plt.savefig(\"{}/groups_difficulty_barplots_{}_top{}_rankedby_{}_logscale.pdf\".format(figures_folder, parameter, rank_parameter, topn))\n",
    "    else:\n",
    "        plt.savefig(\"{}/groups_difficulty_barplots_{}_top{}_rankedby_{}.pdf\".format(figures_folder, parameter, topn, rank_parameter))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_parameters = ['S_geom_casp14', 'GDT_TS', 'GDT_HA', 'GDC_SC', 'Model_DipDiff', 'Model_BBscore', 'Model_SCscore']\n",
    "for p in target_parameters:\n",
    "    print('CURRENT PARAMETER: {}'.format(p))\n",
    "    groups_barplots(df_1st, p, palette = 'Spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Check which parameters correlate with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df = df.drop(['GR#', 'Target_title', 'Target', 'Model_GR_rank', 'Target_difficulty', 'Target_Neff', 'err', '#Residues', 'Model_CaBLAMdiff', 'LLG_const_B', 'Model_ChiDiff'], axis='columns')\n",
    "z_columns = [i for i in param_df.columns if i.startswith('Z_') or 'casp' in i or 'Original' in i or 'from_' in i or 'PC' in i or 'Rms' in i or 'corr' in i or 'GR' in i]\n",
    "for col in z_columns:\n",
    "    param_df = param_df.drop([col], axis='columns')\n",
    "\n",
    "param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_corr = param_df.corr(method='pearson')\n",
    "print(params_corr['Model_DipDiff'].sort_values().tail())\n",
    "print(params_corr['Model_DipDiff'].sort_values().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casp14_param = ['LDDT', 'CAD_AA', 'SphGr', 'Model_SCscore', 'MolPrb_clash', 'Model_BBscore', 'Model_DipDiff', 'GDT_HA', 'QSE']\n",
    "casp14_param = param_df[casp14_param]\n",
    "plt.figure(figsize=(30, 30))\n",
    "sns.clustermap(casp14_param.corr(), cmap = 'RdBu_r', center=0, vmin = -1, vmax=1, annot=True).savefig(\"{}/correlation_matrix_Scasp14_measures.pdf\".format(figures_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 30))\n",
    "sns.clustermap(params_corr, cmap = 'RdBu_r', center=0, vmin = -1, vmax=1).savefig(\"{}/correlation_matrix_all_measures.pdf\".format(figures_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compare CASP14 and CASP13 scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(values, cmap = 'Blues_r'):\n",
    "    \n",
    "    colors = {}\n",
    "    \n",
    "    cmap = matplotlib.cm.get_cmap(cmap)\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=len(values))\n",
    "    \n",
    "    colours = [cmap(norm(i)) for i in range(len(values))]\n",
    "    \n",
    "    for i, value in enumerate(values):\n",
    "        colors[value] = colours[i]\n",
    "    \n",
    "    return colors\n",
    "    \n",
    "def compare_casp_functions(df_1st, parameter_x, parameter_y, colorby='GR_classification', groupby = 'GR#', equal_axis = True):\n",
    "    \n",
    "    medians = df_1st.groupby([groupby]).median()\n",
    "    colors = []\n",
    "    for index, row in medians.iterrows():\n",
    "        tmp = df_1st[df_1st[groupby] == index][colorby]\n",
    "        colors.append(tmp[tmp.index[0]])\n",
    "    medians[colorby] = colors\n",
    "    \n",
    "#     colors = get_colors(sorted(set(list(df_1st[colorby]))), cmap = 'Blues')\n",
    "#     gr_colors = {gr: colors[list(set(df_1st[df_1st[groupby] == gr][colorby]))[0]] for gr, row in medians.iterrows()}\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    sns.scatterplot(parameter_x, parameter_y, data = medians, hue = colorby, s=30, edgecolor='k', hue_order=sorted(list(set(colors)))[::-1], palette = 'Blues_r')\n",
    "    \n",
    "#    for index, row in medians.iterrows():\n",
    "        #plt.scatter(row[parameter_x], row[parameter_y],  c=np.array([gr_colors[index]]), edgecolors='k', s=30)\n",
    "        #plt.text(row[parameter_x], row[parameter_y], index, c=gr_colors[index], ha='center', va='center')\n",
    "    \n",
    "    if equal_axis:\n",
    "        \n",
    "        plt.plot([0, 2.5], [0, 2.53], ls=\":\", c='grey')\n",
    "        plt.xlim(0, 2.5)\n",
    "        plt.ylim(0, 2.5)\n",
    "    \n",
    "    plt.ylabel(parameter_y)\n",
    "    plt.xlabel(parameter_x)\n",
    "    \n",
    "    plt.savefig('{}/scatter_groups_ranking_{}_vs_{}_colorby_{}.pdf'.format(figures_folder,parameter_x, parameter_y, colorby))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_columns = ['S_geom_casp13', 'S_geom_casp14']\n",
    "\n",
    "for i, x in enumerate(target_columns):\n",
    "    for j, y in enumerate(target_columns):\n",
    "        if i < j:\n",
    "            compare_casp_functions(df_1st, x, y, groupby='GR_name', colorby='GR_type')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Check accuracy accross CASPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_casps(parameter, cancelled_targets = cancelled_targets, which_casps = [12,13,14], exclude_group = None, difficulty = 'Target_difficulty'):\n",
    "\n",
    "    tmp = {difficulty:[], parameter: [], 'CASP': [], 'Target_type': []}\n",
    "    \n",
    "    for casp in which_casps:\n",
    "        if casp != 14:\n",
    "            cancelled_targets = []\n",
    "        else:\n",
    "            cancelled_targets = cancelled_targets\n",
    "            \n",
    "        df = load_casp_zscore_table(casp, cancelled_targets, domains_only = True)\n",
    "        df = df[df.Model.str.startswith('T')]\n",
    "        \n",
    "        for target in set(list(df.Target)):\n",
    "            tmp_df = df.loc[(df.Target == target)].sort_values(by='GDT_HA', ascending=False)\n",
    "            \n",
    "            if casp == 14:\n",
    "                tmp_df = tmp_df.loc[(df['GR#'] != exclude_group)]\n",
    "                \n",
    "            target_type = list(tmp_df.Target_classification)[0]\n",
    "            try:\n",
    "                target_type = target_type.split('-')[0]\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            tmp[parameter].append(list(tmp_df[parameter])[0])\n",
    "            tmp[difficulty].append(list(tmp_df[difficulty])[0])\n",
    "            tmp['CASP'].append(str(casp))\n",
    "            tmp['Target_type'].append(target_type)\n",
    "\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    \n",
    "    if difficulty == 'Target_difficulty':\n",
    "        tmp[difficulty] = 100-tmp[difficulty]\n",
    "    \n",
    "    print('Exclude Group {}'.format(exclude_group))\n",
    "    \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    sns.lmplot(x=difficulty, y=parameter, data=tmp, hue='CASP', markers=[\".\", \"x\", '+'], lowess=True, palette='nipy_spectral_r', height=3, aspect=1) \n",
    "    if difficulty == 'Target_difficulty':\n",
    "        plt.xlim(0,100)\n",
    "    else:\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    if 'GD' in parameter:\n",
    "        plt.ylim(0,100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if exclude_group is None:\n",
    "        plt.savefig(\"{}/CASPs_{}_vs_{}_comparison.pdf\".format(figures_folder, difficulty, parameter))\n",
    "    else:\n",
    "        plt.savefig(\"{}/CASPs_{}_vs_{}_comparison-excluding_{}.pdf\".format(figures_folder, difficulty, parameter, exclude_group))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "paremeters = ['GDT_HA', 'Model_BBscore', 'Model_SCscore', 'Model_DipDiff']\n",
    "for parameter in paremeters:\n",
    "    compare_casps(parameter)\n",
    "    compare_casps(parameter, exclude_group='427')\n",
    "    \n",
    "# for parameter in paremeters:\n",
    "#     compare_casps(parameter, difficulty = 'Target_Neff')\n",
    "#     compare_casps(parameter, difficulty = 'Target_Neff', exclude_group='427')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
